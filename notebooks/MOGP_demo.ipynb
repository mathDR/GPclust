{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixtures of Gaussian Processes with GPclust\n",
    "\n",
    "\n",
    "This notebook accompanies the paper\n",
    "\n",
    "**Nonparameteric Clustering of Structured Time Series**  \n",
    "_James Hensman, Magnus Rattray and Neil D. Lawrence_  \n",
    "IEEE TPAMI 2014\n",
    "\n",
    "The code is available at <https://github.com/mathDR/gpclust> . The GPclust module depends on [GPflow](https://github.com/GPflow).  \n",
    "\n",
    "The hierachical Gaussian process model was fleshed out in \n",
    "\n",
    "**Hierarchical Bayesian modelling of gene expression time series  \n",
    "across irregularly sampled replicates and clusters**  \n",
    "_James Hensman, Neil D. Lawrence and Magnus Rattray_\n",
    "\n",
    "http://www.biomedcentral.com/1471-2105/14/252\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'#'svg' would be better, but eats memory for these big plots.\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "import random\n",
    "import GPclust\n",
    "import GPflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple point process dataset\n",
    "\n",
    "Here's a simulated dataset that contains the simple features that we expect to have in real data sets: . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generate a data set. Here we generate Poisson process counts with a different rate mean for each cluster\n",
    "Nclust = 10\n",
    "Nobs = [np.random.randint(20,31) for i in range(Nclust)] #a random number of realisations in each cluster\n",
    "Nx = 156 # number of time steps for each realization ( 3 years if weekly data)\n",
    "\n",
    "#random rate function for each cluster (between 0.5 and 5.5)\n",
    "means = (5.0*np.random.rand(Nclust)+.5)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for n in xrange(Nclust):\n",
    "    for j in xrange(Nobs[n]):\n",
    "        Y.append(np.random.poisson(means[n],Nx)[:,None])\n",
    "        X.append(np.asarray(range(Nx))[:,None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 1)\n"
     ]
    }
   ],
   "source": [
    "print (X[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot below, we show the underlying function for each cluster as a smooth red function, and the data associated with the cluster as thinly connected blue crosses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    bins = range(10)\n",
    "    denom = [np.math.factorial(b) for b in bins]\n",
    "    count = 0\n",
    "    for n in range(Nclust):\n",
    "        plt.subplot(2,Nclust/2,n+1)\n",
    "        for j in range(Nobs[n]):\n",
    "            plt.hist(Y[count], bins, alpha=1.0/Nobs[n], color = 'red', normed=True, align='left')\n",
    "            count = count + 1\n",
    "        plt.plot(bins,np.power(means[n],bins)*np.exp(-means[n])/denom,'b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing and optimizing a model\n",
    "---\n",
    "\n",
    "Now that we have generated a data set, it's straightforward to build and optimize a clustering model. First, we need to build two GPy kernels (covariance functions), which will be used to model the underlying function and the replication noise, respecively. We'll take a wild stab at the parameters of these covariances, and let the model optimize them for us later. \n",
    "\n",
    "The two kernels model the *underlying* function of the cluster, and the deviations of each gene from that underlying function. If we believe that the only corruption of the data from the cluster mean is i.i.d. noise, we can specify a `GPy.kern.White` covariance. In practice, it's helpful to allow correlated noise. The model of any cluster of genes then has a hierarchical structure, with the unknown cluster-specific mean drawn from a GP, and then each gene in that cluster being drawn from a GP with said unknown mean function. \n",
    "\n",
    "To optimize the model with the default optimization settings, we call `m.optimize()`. To invoke the recommended merge-split procedure, call `m.systematic_splits()`. Note that during the splitting procedure, many calls are made to the optimize function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = np.linspace(np.min(X), np.max(X),10)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k_underlying = GPflow.kernels.RBF(input_dim=X[0].shape[0], variance=0.1, lengthscales=0.1)\n",
    "#k_corruption = GPflow.kernels.RBF(input_dim=1, variance=0.01, lengthscales=0.1) + GPflow.kernels.White(1, variance=0.001)\n",
    "likelihood = GPflow.likelihoods.Poisson()\n",
    "\n",
    "m = GPclust.MOGP(X, Y, Z, k_underlying, likelihood, num_clusters=10, alpha=1.0, prior_Z='symmetric')\n",
    "#m.optimize()\n",
    "m.systematic_splits(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-156464.20536226252"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.log_likelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
